# architecture
model: "vit"
spatial_dims : 2
embed_dim : 768
depth : 12
num_heads : 12
qkv_bias: True
dp: 0
out_channels : 256
model_patch_size : 16
mlp_dim : 3072
n_input_channels : 1
decoder_type: 'upsample'
conv_bias: False
conv_layernorm: False

#dataset info
dataset: "eyeq"
data_channels : 3
img_size : 2048
scale_factor : 4
data_base_dir: /orange/bianjiang/tienyu/EyePACS
tfevent_path: /blue/bianjiang/tienyuchang/super_resol/eyeq
result_list_file_path: /blue/bianjiang/tienyuchang/result/result_eyeq.json

#train setting
optimizer: adam
wd: 0
lr: 1.0e-4
scheduler_step : 10
scheduler_gamma : 0.3
warmup_epochs : 10
warmup_multi : 1
finetune_epochs : 50
val_interval : 5
batch_size : 16
amp : False
model_path: "/blue/bianjiang/tienyuchang/super_resol_model/model_eyeq_upsam.pt"

#pre-trained model
checkpoint_path: "/orange/bianjiang/Image_dataset/checkpoints/ssl-framework/dinov2_vit_pretrained/dinov2_vitb14_reg4_pretrain.pth"
state_key: ''
trans_dic:
  #patch_embed.proj.: feature_extractor.body.patch_embedding.patch_embeddings.
  .fc: .linear
  blocks.: encoder.blocks.
  norm.: encoder.norm.
init_values: 1.0
