# architecture
model: "vit"
spatial_dims : 2
embed_dim : 768
depth : 12
num_heads : 12
qkv_bias: True
dp: 0
out_channels : 256
model_patch_size : 16
mlp_dim : 3072
n_input_channels : 1
decoder_type: 'conv'
conv_bias: True
conv_layernorm: True

#dataset info
dataset: "eyeq"
data_channels : 3
img_size : 2048
scale_factor : 4
data_base_dir: /orange/bianjiang/tienyu/EyePACS
tfevent_path: /blue/bianjiang/tienyuchang/super_resol/eyeq
result_list_file_path: /blue/bianjiang/tienyuchang/result/result_eyeq.json

#train setting
optimizer: adam
wd: 0
lr: 1.0e-4
scheduler_step : 10
scheduler_gamma : 0.3
warmup_epochs : 10
warmup_multi : 1
finetune_epochs : 50
val_interval : 5
batch_size : 16
amp : False
model_path: "/blue/bianjiang/tienyuchang/super_resol_model/model_eyeq_conv.pt"

#pre-trained model
state_key: state_dict
trans_dic:
  .patch_embed.proj: .patch_embedding.patch_embeddings 
  .fc: .linear
