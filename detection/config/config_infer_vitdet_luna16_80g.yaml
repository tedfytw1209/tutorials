---
# architecture
model: vitdet
model_spatial_dims: 2
embed_dim: 768
depth: 12
num_heads: 12
dp: 0.1
img_size: 192
out_channels: 256
model_patch_size: 16
window_size: 6
mlp_dim: 3072
n_input_channels: 1
scale_factors:
- 4
- 2
- 1
window_block_indexes:
- 0
- 1
- 3
- 4
- 6
- 7
- 9
- 10

#dataset & detector
gt_box_mode: cccwhd
spacing:
- 0.703125
- 0.703125
- 1.25
patch_size:
- 192
- 192
- 1
val_patch_size:
- 192
- 192
- 1
fg_labels:
- 0
spatial_dims: 3
score_thresh: 0.02
nms_thresh: 0.22
returned_layers:
- 1
- 2
base_anchor_shapes:
- - 6
  - 8
  - 1
- - 8
  - 6
  - 1
- - 10
  - 10
  - 1
balanced_sampler_pos_fraction: 0.3

#training setting
lr: 0.01
scheduler_step : 25
scheduler_gamma : 0.3
warmup_epochs : 10
w_cls: 1
finetune_epochs: 50
val_interval: 5
amp: False
batch_size: 8

#pre-train model
state_key: state_dict
trans_dic:
  .patch_embed.proj: .patch_embedding.patch_embeddings
  .fc: .linear
  encoder.: feature_extractor.body.
